{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "'/Users/marianne/documents/pe_snow_fires/stylefile.mplstyle' not found in the style library and input is not a valid URL or path; see `style.available` for list of available styles",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/earthenv/lib/python3.9/site-packages/matplotlib/style/core.py\u001b[0m in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrc_params_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_default_template\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0m_apply_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/earthenv/lib/python3.9/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36mrc_params_from_file\u001b[0;34m(fname, fail_on_error, use_default_template)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \"\"\"\n\u001b[0;32m--> 798\u001b[0;31m     \u001b[0mconfig_from_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_rc_params_in_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfail_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfail_on_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/earthenv/lib/python3.9/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m_rc_params_in_file\u001b[0;34m(fname, transform, fail_on_error)\u001b[0m\n\u001b[1;32m    726\u001b[0m     \u001b[0mrc_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_or_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/earthenv/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/earthenv/lib/python3.9/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36m_open_file_or_url\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    704\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 705\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m             \u001b[0;32myield\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/marianne/documents/pe_snow_fires/stylefile.mplstyle'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pj/dwdbrbvs73j111lmlw52vz8m0000gn/T/ipykernel_16547/2046036853.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhome_dir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'stylefile.mplstyle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/earthenv/lib/python3.9/site-packages/matplotlib/style/core.py\u001b[0m in \u001b[0;36muse\u001b[0;34m(style)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0m_apply_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 raise IOError(\n\u001b[0m\u001b[1;32m    119\u001b[0m                     \u001b[0;34m\"{!r} not found in the style library and input is not a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0;34m\"valid URL or path; see `style.available` for list of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: '/Users/marianne/documents/pe_snow_fires/stylefile.mplstyle' not found in the style library and input is not a valid URL or path; see `style.available` for list of available styles"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import rasterio\n",
    "from rasterio.plot import show, adjust_band\n",
    "from matplotlib import cm\n",
    "import matplotlib\n",
    "from scipy import stats\n",
    "import datetime\n",
    "from constants import *\n",
    "\n",
    "os.chdir(home_dir)\n",
    "plt.style.use(home_dir+'stylefile.mplstyle')\n",
    "\n",
    "tmp = []\n",
    "for i in range(len(fire_sn)):\n",
    "    tmp.append(datetime.datetime.strptime(fire_sn['Ig_Date'][i], '%Y-%m-%d'))\n",
    "fire_sn['dt'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(30,30))\n",
    "sn_watersheds.boundary.plot(ax=ax)\n",
    "for i in sn_watersheds.index:\n",
    "    tmp = sn_watersheds[(sn_watersheds.index==i)]\n",
    "    x = (tmp.bounds.minx[i]+tmp.bounds.maxx[i])/2\n",
    "    y = (tmp.bounds.miny[i]+tmp.bounds.maxy[i])/2\n",
    "    name = tmp.name[i]\n",
    "    ax.text(x,y,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# san joaquin watershed\n",
    "targets = ['Upper San Joaquin','Upper Tuolumne']\n",
    "names = sn_watersheds.name\n",
    "tmp =[names[i] in targets for i in range(len(names))]\n",
    "idx = np.arange(44)[tmp]\n",
    "tmp1 = sn_watersheds[sn_watersheds.index == 1]\n",
    "tmp2 = sn_watersheds[sn_watersheds.index == 2]\n",
    "tmp3 = tmp1.append(tmp2)\n",
    "tmp3\n",
    "\n",
    "# san joaquin watershed\n",
    "targets = ['Upper San Joaquin','Upper Tuolumne','Upper King','Upper Merced','Upper Kaweah','Upper Kern','Upper Tule']\n",
    "sj = sn_watersheds[sn_watersheds.name == targets[0]]\n",
    "for t in range(1,len(targets)):\n",
    "    tmp = sn_watersheds[(sn_watersheds.name==targets[t])]\n",
    "    sj = sj.append(tmp)\n",
    "sj.name\n",
    "sj.to_file('upper_watersheds.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_sw = ['Upper San Joaquin','Upper Tuolumne','Upper King','Upper Merced','Upper Kaweah','Upper Kern','Upper Tule','South Fork Kern']\n",
    "targets_se = ['West Walker','East Walker','Mono Lake','Crowley Lake','Owens Lake','Indian Wells-Searles Valley']\n",
    "targets_ne = ['East Branch North Fork Feather','Middle Fork Feather','Truckee','Lake Tahoe','Upper Carson']\n",
    "targets_nw = ['Upper Yuba','North Fork American','South Fork American','Upper Cosumnes','Upper Mokelumne','Upper Stanislaus']\n",
    "targets_all = [targets_sw,targets_se,targets_ne,targets_nw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(10,10))\n",
    "# sn_watersheds.boundary.plot(ax=ax)\n",
    "colors = ['blue','red','orange','green']\n",
    "\n",
    "for i,targets in enumerate(targets_all):\n",
    "    sheds = sn_watersheds[sn_watersheds.name == targets[0]]\n",
    "    for t in range(1,len(targets)):\n",
    "        tmp = sn_watersheds[(sn_watersheds.name==targets[t])]\n",
    "        try:\n",
    "            tmp = tmp[tmp.index==tmp.index[0]]\n",
    "        except:\n",
    "            continue\n",
    "        #print(len(tmp))\n",
    "        #x = (tmp.bounds.minx[i]+tmp.bounds.maxx[i])/2\n",
    "        # y = (tmp.bounds.miny[i]+tmp.bounds.maxy[i])/2\n",
    "        #name = tmp.name[i]\n",
    "        #ax.text(x,y,name)\n",
    "        sheds = sheds.append(tmp)\n",
    "    sheds.plot(ax=ax, color = colors[i],alpha = 0.5)\n",
    "    #print(sheds)\n",
    "    print(i)\n",
    "\n",
    "'''\n",
    "for i in sn_watersheds.index:\n",
    "    tmp = sn_watersheds[(sn_watersheds.index==i)]\n",
    "    x = (tmp.bounds.minx[i]+tmp.bounds.maxx[i])/2\n",
    "    y = (tmp.bounds.miny[i]+tmp.bounds.maxy[i])/2\n",
    "    name = tmp.name[i]\n",
    "    ax.text(x,y,name)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def watershed_data_burned(targets,filename):\n",
    "    sj = sn_watersheds[sn_watersheds.name == targets[0]]\n",
    "\n",
    "    for t in range(1,len(targets)):\n",
    "        tmp = sn_watersheds[(sn_watersheds.name==targets[t])]\n",
    "        sj = sj.append(tmp)\n",
    "    \n",
    "    import datetime\n",
    "\n",
    "    fire_time = 10 #yrs\n",
    "    swe_sj = {}\n",
    "    swe_sj_burned = {}\n",
    "    swe_sj_unburned = {}\n",
    "    sai_sj = {}\n",
    "    sai_sj_burned = {}\n",
    "    sai_sj_unburned = {}\n",
    "\n",
    "    gpp_sj = {}\n",
    "    gpp_tot_sj ={}\n",
    "    gpp_sj_burned = {}\n",
    "    gpp_sj_unburned = {}\n",
    "    gpp_tot_sj_burned ={}\n",
    "    gpp_tot_sj_unburned ={}\n",
    "    ndvi_sj = {}\n",
    "    ndvi_sj_burned = {}\n",
    "    ndvi_sj_unburned = {}\n",
    "    for yr in range(2000,2016):\n",
    "        timestop =datetime.datetime(yr,10,1)\n",
    "        timestart = datetime.datetime(yr-fire_time,10,1)\n",
    "        prev_fires = fire_sn[fire_sn['dt']<timestop]\n",
    "        prev_fires = prev_fires[prev_fires['dt']>timestart]\n",
    "\n",
    "        swe = rxr.open_rasterio(data_dir + 'max_swe'+str(yr)+'.tif')\n",
    "        swe = swe.rio.write_crs(sj.crs)\n",
    "        clipped = swe.rio.clip(sj.geometry,all_touched=True,from_disk=False)\n",
    "        clipped.rio.set_nodata(np.nan)\n",
    "        swe_sj[yr]=clipped\n",
    "        out_fire = clipped.rio.clip(prev_fires.geometry, from_disk=False, invert = True)\n",
    "        swe_sj_unburned[yr]=out_fire\n",
    "        in_fire = clipped.rio.clip(prev_fires.geometry, all_touched= True, from_disk = True)\n",
    "        swe_sj_burned[yr]=in_fire\n",
    "  #SAI\n",
    "        sai = rxr.open_rasterio(pe_data_dir + 'sai_'+str(yr)+'.tif')\n",
    "        clipped = sai.rio.clip(sj.geometry,all_touched=True)\n",
    "        clipped.rio.set_nodata(np.nan)\n",
    "        clipped[np.where(clipped==np.inf)]=np.nan\n",
    "        clipped[np.where(clipped>3000)]=np.nan\n",
    "        clipped[np.where(clipped<0)]=np.nan\n",
    "        sai_sj[yr]=clipped\n",
    "        out_fire= clipped.rio.clip(prev_fires.geometry, from_disk=False, invert = True)\n",
    "        sai_sj_unburned[yr] = out_fire\n",
    "        in_fire = clipped.rio.clip(prev_fires.geometry, all_touched= True, from_disk=False)\n",
    "        sai_sj_burned[yr]=in_fire\n",
    "        # GPP\n",
    "        id = yr-2000\n",
    "        gpp_means = []\n",
    "        gpp_means_burned = []\n",
    "        gpp_means_unburned = []\n",
    "        gpp_all = {}\n",
    "        gpp_all_burned = {}\n",
    "        gpp_all_unburned = {}\n",
    "        for mo in range(1,13):\n",
    "            gppmean = 0\n",
    "            gppmean_burned = 0\n",
    "            try:\n",
    "                tmp = rxr.open_rasterio(data_dir + 'modis_clip_'+str(id)+'_'+str(mo)+'.tif')\n",
    "                clipped = tmp.rio.clip(sj.geometry,all_touched=True)\n",
    "                clipped[np.where(clipped>5000)] = np.nan\n",
    "                gppmean = np.nanmean(clipped)\n",
    "                gpp_all[mo]=clipped\n",
    "                out_fire= clipped.rio.clip(prev_fires.geometry, from_disk=False, invert = True)\n",
    "                in_fire = clipped.rio.clip(prev_fires.geometry, all_touched= True, from_disk=False)\n",
    "                gpp_all_burned[mo]=in_fire\n",
    "                gpp_all_unburned[mo]=out_fire\n",
    "                gppmean_burned = np.nanmean(in_fire)\n",
    "                gppmean_unburned = np.nanmean(out_fire)\n",
    "            except:\n",
    "                continue\n",
    "            gpp_means.append(gppmean)\n",
    "            gpp_means_burned.append(gppmean_burned)\n",
    "            gpp_means_unburned.append(gppmean_unburned)\n",
    "        max_mo = np.nanargmax(gpp_means)+1\n",
    "        gpp = rxr.open_rasterio(data_dir+'modis_clip_'+str(id)+'_'+str(max_mo)+'.tif')\n",
    "        clipped = gpp.rio.clip(sj.geometry,all_touched=True)\n",
    "        clipped.rio.set_nodata(np.nan)\n",
    "        clipped[np.where(clipped>5000)] = np.nan\n",
    "        gpp_sj[yr]=clipped\n",
    "        out_fire= clipped.rio.clip(prev_fires.geometry, from_disk=False, invert = True)\n",
    "        in_fire = clipped.rio.clip(prev_fires.geometry, all_touched= True, from_disk=False)\n",
    "        gpp_sj_burned[yr]=in_fire\n",
    "        gpp_sj_unburned[yr]=out_fire\n",
    "        gpp_sum = np.zeros((clipped.shape[1:]))\n",
    "        for k in gpp_all.keys():\n",
    "            gpp_sum += gpp_all[k][0,:,:]\n",
    "        gpp_tot_sj[yr]=gpp_sum\n",
    "        gpp_sum_burned = np.zeros((in_fire.shape[1:]))\n",
    "        gpp_sum_unburned = np.zeros((out_fire.shape[1:]))\n",
    "        for k in gpp_all_burned.keys():\n",
    "            gpp_sum_burned += gpp_all_burned[k][0,:,:]\n",
    "        gpp_tot_sj_burned[yr]=gpp_sum_burned\n",
    "        for k in gpp_all_unburned.keys():\n",
    "            gpp_sum_unburned += gpp_all_unburned[k][0,:,:]\n",
    "        gpp_tot_sj_unburned[yr]=gpp_sum_unburned\n",
    "\n",
    "\n",
    "\n",
    "        #NDVI\n",
    "        ndvi = rxr.open_rasterio(data_dir + 'pe_snow_fires_data/max-ndvi/max-ndvi-' + str(yr)+'.tif')\n",
    "        #pe = pe.rio.write_crs(sj.crs)\n",
    "        clipped = ndvi.rio.clip(sj.geometry,all_touched=True)\n",
    "        clipped.rio.set_nodata(np.nan)\n",
    "        out_fire= clipped.rio.clip(prev_fires.geometry, from_disk=False, invert = True)\n",
    "        in_fire = clipped.rio.clip(prev_fires.geometry, all_touched= True, from_disk=False, invert = False)\n",
    "        ndvi_sj[yr]=clipped\n",
    "        ndvi_sj_burned[yr]=in_fire\n",
    "        ndvi_sj_unburned[yr] = out_fire\n",
    "    \n",
    "    gpp_by_month = np.zeros((clipped.shape[1:]))\n",
    "    gpp_by_month_burned = np.zeros((clipped.shape[1:]))\n",
    "    gpp_by_month_unburned = np.zeros((clipped.shape[1:]))\n",
    "\n",
    "    for yr in range(2000,2016):\n",
    "        for mo in range(1,13):\n",
    "                gppmean = 0\n",
    "                gppmean_burned = 0\n",
    "                try:\n",
    "                    tmp = rxr.open_rasterio(data_dir + 'modis_clip_'+str(yr-2000)+'_'+str(mo)+'.tif')\n",
    "                    clipped = tmp.rio.clip(sj.geometry,all_touched=True)\n",
    "                    clipped[np.where(clipped>5000)] = np.nan\n",
    "                    gppmean = np.nanmean(clipped)\n",
    "                    gpp_by_month[yr-2000, mo-1] = gppmean\n",
    "                    in_fire = clipped.rio.clip(prev_fires.geometry, all_touched= True, from_disk = True)\n",
    "                    gpp_all_burned[mo]=in_fire\n",
    "                    gppmean_burned = np.nanmean(in_fire)\n",
    "                    gpp_by_month_burned[yr-2000, mo-1] = gppmean_burned\n",
    "                    out_fire = clipped.rio.clip(prev_fires.geometry, all_touched= False, from_disk = True,invert=True)\n",
    "                    gppmean_unburned = np.nanmean(out_fire)\n",
    "                    gpp_by_month_unburned[yr-2000, mo-1] = gppmean_unburned\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    keys = range(2000,2015)\n",
    "    swe_means = [np.nanmean(swe_sj[k]) for k in keys]\n",
    "    sai_means = [np.nanmean(sai_sj[k]) for k in keys]\n",
    "    gpp_means = [np.nanmean(gpp_sj[k+1]) for k in keys]\n",
    "    ndvi_means = [np.nanmean(ndvi_sj[k+1]) for k in keys]\n",
    "    gpp_tot_means = [np.nanmean(gpp_tot_sj[k+1]) for k in keys]\n",
    "    swe_means_burned = [np.nanmean(swe_sj_burned[k]) for k in keys]\n",
    "    sai_means_burned = [np.nanmean(sai_sj_burned[k]) for k in keys]\n",
    "    gpp_means_burned = [np.nanmean(gpp_sj_burned[k+1]) for k in keys]\n",
    "    ndvi_means_burned = [np.nanmean(ndvi_sj_burned[k+1]) for k in keys]\n",
    "    gpp_tot_means_burned = [np.nanmean(gpp_tot_sj_burned[k+1]) for k in keys]\n",
    "    swe_means_unburned = [np.nanmean(swe_sj_unburned[k]) for k in keys]\n",
    "    sai_means_unburned = [np.nanmean(sai_sj_unburned[k]) for k in keys]\n",
    "    gpp_means_unburned = [np.nanmean(gpp_sj_unburned[k+1]) for k in keys]\n",
    "    ndvi_means_unburned = [np.nanmean(ndvi_sj_unburned[k+1]) for k in keys]\n",
    "    gpp_tot_means_unburned = [np.nanmean(gpp_tot_sj_unburned[k+1]) for k in keys]\n",
    "\n",
    "    to_save = {'targets':targets,\n",
    "                'swe_means': swe_means,\n",
    "                'sai_means':sai_means,\n",
    "                'gpp_means':gpp_means,\n",
    "                'ndvi_means':ndvi_means,\n",
    "                'gpp_tot_means':gpp_tot_means,\n",
    "                'swe_means_burned': swe_means_burned,\n",
    "                'sai_means_burned':sai_means_burned,\n",
    "                'gpp_means_burned':gpp_means_burned,\n",
    "                'ndvi_means_burned':ndvi_means_burned,\n",
    "                'gpp_tot_means_burned':gpp_tot_means_burned,\n",
    "                'swe_means_unburned': swe_means_unburned,\n",
    "                'sai_means_unburned':sai_means_unburned,\n",
    "                'gpp_means_unburned':gpp_means_unburned,\n",
    "                'ndvi_means_unburned':ndvi_means_unburned,\n",
    "                'gpp_tot_means_unburned':gpp_tot_means_unburned\n",
    "                }\n",
    "    \n",
    "    with open(pe_data_dir + filename + '.pkl', 'wb') as file:\n",
    "        pickle.dump(to_save, file)\n",
    "\n",
    "    return targets\n",
    "\n",
    "\n",
    "def plot_linear_four(xvar,yvar):\n",
    "    f,ax=plt.subplots(2,2,figsize=(15,10))\n",
    "    axs = ax.flatten()\n",
    "    for k,region in enumerate(['northwest','northeast','southwest','southeast']):\n",
    "        with open(pe_data_dir + region + '.pkl', 'rb') as file:\n",
    "            data = pickle.load(file)\n",
    "\n",
    "        x_b = normalize(data[xvar+'_means_burned'])\n",
    "        y_b = normalize(data[yvar+'_means_burned'])\n",
    "        x_u = normalize(data[xvar+'_means_unburned'])\n",
    "        y_u = normalize(data[yvar+'_means_unburned'])\n",
    "\n",
    "        n = 1  # degree of polynomial\n",
    "        \n",
    "        p_b, C_p_b = np.polyfit(x_b, y_b, n, cov=True)  # C_p is estimated covariance matrix\n",
    "        t_b = np.linspace(min(x_b), max(x_b), 500)\n",
    "        TT_b = np.vstack([t_b**(n-i) for i in range(n+1)]).T\n",
    "        yi_b = np.dot(TT_b, p_b)  # matrix multiplication calculates the polynomial values\n",
    "        C_yi_b = np.dot(TT_b, np.dot(C_p_b, TT_b.T)) # C_y = TT*C_z*TT.T\n",
    "        sig_yi_b = np.sqrt(np.diag(C_yi_b))  # Standard deviations are sqrt of diagonal\n",
    "\n",
    "        p_u, C_p_u = np.polyfit(x_u, y_u, n, cov=True)  # C_p is estimated covariance matrix\n",
    "        t_u = np.linspace(min(x_u), max(x_u), 500)\n",
    "        TT_u = np.vstack([t_u**(n-i) for i in range(n+1)]).T\n",
    "        yi_u = np.dot(TT_u, p_u)  # matrix multiplication calculates the polynomial values\n",
    "        C_yi_u = np.dot(TT_u, np.dot(C_p_u, TT_u.T)) # C_y = TT*C_z*TT.T\n",
    "        sig_yi_u = np.sqrt(np.diag(C_yi_u))  # Standard deviations are sqrt of diagonal\n",
    "\n",
    "        \n",
    "        axs[k].plot(x_b,y_b,'o',color='darkgoldenrod',label='burned')\n",
    "        axs[k].fill_between(t_b, yi_b+sig_yi_b, yi_b-sig_yi_b, alpha=.25,color='darkorange')\n",
    "        axs[k].plot(t_b, yi_b,'-',color='red')\n",
    "\n",
    "        axs[k].plot(x_u,y_u,'o',color='seagreen',label='unburned')\n",
    "        axs[k].fill_between(t_u, yi_u+sig_yi_u, yi_u-sig_yi_u, alpha=.25,color='seagreen')\n",
    "        axs[k].plot(t_u, yi_u,'-',color='seagreen')\n",
    "        slope_b, intercept_b, r_value_b, p_value_b, std_err_b = stats.linregress(x_b, y_b)\n",
    "        slope_u, intercept_u, r_value_u, p_value_u, std_err_u = stats.linregress(x_u, y_u)\n",
    "\n",
    "        if(k>1): axs[k].set_xlabel(xvar)\n",
    "        if(k%2==0): axs[k].set_ylabel(yvar)\n",
    "        axs[k].set_title(region)\n",
    "    #ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "watershed_data_burned(targets=targets_sw,filename = 'southwest')\n",
    "watershed_data_burned(targets=targets_se,filename = 'southeast')\n",
    "watershed_data_burned(targets=targets_ne,filename = 'northeast')\n",
    "watershed_data_burned(targets=targets_nw,filename = 'northwest')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_linear_four(xvar = 'swe',yvar = 'ndvi')\n",
    "\n",
    "plot_linear_four(xvar = 'swe',yvar = 'gpp')\n",
    "\n",
    "\n",
    "#plot_linear(region = 'southeast',xvar = 'swe',yvar = 'gpp_tot')\n",
    "#plot_linear(region = 'northeast',xvar = 'swe',yvar = 'gpp_tot')\n",
    "#plot_linear(region = 'southwest',xvar = 'swe',yvar = 'gpp_tot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(20,7))\n",
    "for yr in range(2000,2015):\n",
    "    months = range(3,9)\n",
    "    midx = [m-1 for m in months]\n",
    "    data= gpp_by_month_unburned[yr-2000,midx]\n",
    "    dates = [datetime.datetime(yr,m,1) for m in months]\n",
    "    ax.plot(dates,data,'k-')\n",
    "    ax.scatter(dates,data,c=range(6), cmap='BrBG',s=130, zorder=2.5)\n",
    "\n",
    "for yr in range(2000,2015):\n",
    "    months = range(3,9)\n",
    "    midx = [m-1 for m in months]\n",
    "    data= gpp_by_month_burned[yr-2000,midx]\n",
    "    dates = [datetime.datetime(yr,m,1) for m in months]\n",
    "    ax.plot(dates,data,'k-')\n",
    "    ax.scatter(dates,data,c=range(6), cmap='Reds',s=130, zorder=2.5)\n",
    "\n",
    "\n",
    "months = range(3,9)\n",
    "texts = ['March','April','May','June','July','August']\n",
    "midx = [m-1 for m in months]\n",
    "n=350\n",
    "data= [n,n,n,n,n,n]\n",
    "yr = 2008\n",
    "dates = [datetime.datetime(yr+m,m,1) for m in months]\n",
    "ax.plot(midx,data,'k-')\n",
    "ax.scatter(midx,data,c=range(6), cmap='BrBG',s=130, zorder=2.5)\n",
    "\n",
    "for i in range(len(midx)):\n",
    "    ax.text(midx[i]-0.45,data[i]-0.0025,texts[i],size=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,ax=plt.subplots(figsize=(15,10))\n",
    "x = normalize(swe_means_burned)\n",
    "y = normalize(ndvi_means_burned)\n",
    "y2 = [y[i+1] for i in range(len(y)-1)]\n",
    "idx=np.nanargmax(y)\n",
    "x2 = x[0:-1]\n",
    "#x = np.delete(x,idx)\n",
    "#y = np.delete(y,idx)\n",
    "#x = swe_means_burned\n",
    "#y = gpp_means_burned\n",
    "ax.plot(x,y,'o',color='darkgoldenrod',label='burned')\n",
    "\n",
    "ax.plot(x2,y2,'o',color='black',label='burned')\n",
    "z = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(z)\n",
    "#ax.plot(x,p(x),\"r--\")\n",
    "\n",
    "n = 1  # degree of polynomial\n",
    "p, C_p = np.polyfit(x, y, n, cov=True)  # C_p is estimated covariance matrix\n",
    "\n",
    "# Do the interpolation for plotting:\n",
    "t = np.linspace(min(x), max(x), 500)\n",
    "# Matrix with rows 1, t, t**2, ...:\n",
    "TT = np.vstack([t**(n-i) for i in range(n+1)]).T\n",
    "yi = np.dot(TT, p)  # matrix multiplication calculates the polynomial values\n",
    "C_yi = np.dot(TT, np.dot(C_p, TT.T)) # C_y = TT*C_z*TT.T\n",
    "sig_yi = np.sqrt(np.diag(C_yi))  # Standard deviations are sqrt of diagonal\n",
    "\n",
    "ax.fill_between(t, yi+sig_yi, yi-sig_yi, alpha=.25,color='darkorange')\n",
    "ax.plot(t, yi,'-',color='red')\n",
    "\n",
    "z = np.polyfit(x2, y2, 1)\n",
    "p = np.poly1d(z)\n",
    "#ax.plot(x,p(x),\"r--\")\n",
    "\n",
    "n = 1  # degree of polynomial\n",
    "p, C_p = np.polyfit(x2, y2, n, cov=True)  # C_p is estimated covariance matrix\n",
    "\n",
    "# Do the interpolation for plotting:\n",
    "t = np.linspace(min(x2), max(x2), 500)\n",
    "# Matrix with rows 1, t, t**2, ...:\n",
    "TT = np.vstack([t**(n-i) for i in range(n+1)]).T\n",
    "yi = np.dot(TT, p)  # matrix multiplication calculates the polynomial values\n",
    "C_yi = np.dot(TT, np.dot(C_p, TT.T)) # C_y = TT*C_z*TT.T\n",
    "sig_yi = np.sqrt(np.diag(C_yi))  # Standard deviations are sqrt of diagonal\n",
    "\n",
    "ax.fill_between(t, yi+sig_yi, yi-sig_yi, alpha=.25,color='black')\n",
    "ax.plot(t, yi,'-',color='black')\n",
    "#ax.axis('tight')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "print(slope, r_value**2,p_value)\n",
    "\n",
    "x = normalize(swe_means_unburned)\n",
    "y = normalize(ndvi_means_unburned)\n",
    "ax.plot(x,y,'o',color='seagreen',label='unburned')\n",
    "n = 1  # degree of polynomial\n",
    "p, C_p = np.polyfit(x, y, n, cov=True)  # C_p is estimated covariance matrix\n",
    "\n",
    "# Do the interpolation for plotting:\n",
    "t = np.linspace(min(x), max(x), 500)\n",
    "TT = np.vstack([t**(n-i) for i in range(n+1)]).T\n",
    "yi = np.dot(TT, p)  # matrix multiplication calculates the polynomial values\n",
    "C_yi = np.dot(TT, np.dot(C_p, TT.T)) # C_y = TT*C_z*TT.T\n",
    "sig_yi = np.sqrt(np.diag(C_yi))  # Standard deviations are sqrt of diagonal\n",
    "\n",
    "ax.fill_between(t, yi+sig_yi, yi-sig_yi, alpha=.25,color='seagreen')\n",
    "ax.plot(t, yi,'-',color='seagreen')\n",
    "#ax.axis('tight')\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(x, y)\n",
    "\n",
    "#z = np.polyfit(x, y, 1)\n",
    "#p = np.poly1d(z)\n",
    "#ax.plot(x,p(x),\":\",color='seagreen')\n",
    "ax.set_xlabel('SWE')\n",
    "ax.set_ylabel('Total summer GPP')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=2000\n",
    "f,ax=plt.subplots()\n",
    "swe_sj_burned[k].plot(ax=ax,cmap='Reds')\n",
    "swe_sj_unburned[k].plot(ax=ax,cmap='Blues')\n",
    "plt.show()\n",
    "k=2015\n",
    "f,ax=plt.subplots()\n",
    "sai_sj_burned[k].plot(ax=ax,cmap='Reds')\n",
    "sai_sj_unburned[k].plot(ax=ax,cmap='Greens')\n",
    "plt.show()\n",
    "k=2000\n",
    "f,ax=plt.subplots()\n",
    "ndvi_sj_burned[k].plot(ax=ax,cmap='Reds')\n",
    "#ndvi_sj_unburned[k].plot(ax=ax,cmap='Greens')\n",
    "plt.show()\n",
    "k=2000\n",
    "f,ax=plt.subplots()\n",
    "gpp_sj_burned[k].plot(ax=ax,cmap='Reds')\n",
    "gpp_sj_unburned[k].plot(ax=ax,cmap='Greens')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d805da05da2befce44113386a6b383db81baed553e6363c924410f071efc3371"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('earthenv': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
